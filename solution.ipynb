{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2.1 - Value-Funktion für eine Grid-World Umgebung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klassendefinition für das Grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Direction(Enum):\n",
    "    RIGHT = (0, 1)\n",
    "    LEFT = (0, -1)\n",
    "    UP = (-1, 0)\n",
    "    DOWN = (1, 0)\n",
    "\n",
    "\n",
    "class GridWorld:\n",
    "\n",
    "    def __init__(self):\n",
    "        state_dtype = np.dtype([('key', 'U2'), ('state_value', 'f4')])\n",
    "        self.grid = np.array([[(None, 0) for _ in range(5)]\n",
    "                             for _ in range(5)], dtype=state_dtype)\n",
    "        self.grid[0, 1]['key'] = 'A'\n",
    "        self.grid[0, 3]['key'] = 'B'\n",
    "        self.grid[4, 1]['key'] = 'A_'\n",
    "        self.grid[2, 3]['key'] = 'B_'\n",
    "\n",
    "    def move(self, position, direction: Direction):\n",
    "        # basically (pos[0]+dir[0], pos[1]+dir[1])\n",
    "        new_position = tuple(sum(x) for x in zip(position, direction.value))\n",
    "\n",
    "        if self.grid[position]['key'] == 'A':\n",
    "            new_position = (4,1)\n",
    "            return 10, new_position\n",
    "\n",
    "        elif self.grid[position]['key'] == 'B':\n",
    "            new_position = (2,3)\n",
    "            return 5, new_position\n",
    "        \n",
    "        if new_position[0] < 0 or new_position[1] < 0 or new_position[0] > 4 or new_position[1] > 4:\n",
    "            return -1, position\n",
    "        else:\n",
    "            return 0, new_position\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) - State Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterativer Algorithmus zur Bestimmung der State Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STATUS ---\n",
      "Grid:\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.5000 | 10.0000 |  2.0000 |  5.0000 |  0.6250 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.3625 |  2.1684 |  0.9379 |  1.3360 |  0.1912 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.3316 |  0.4133 |  0.3040 |  0.3690 | -0.1239 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.3246 |  0.0200 |  0.0729 |  0.0994 | -0.2555 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.5730 | -0.3744 | -0.3178 | -0.2991 | -0.6248 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Greatest value change compared to last iteration:\n",
      "10.0\n",
      "--- END STATUS ---\n",
      "\n",
      "--- STATUS ---\n",
      "Grid:\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  1.4434 |  9.6630 |  3.7102 |  5.3321 |  1.0240 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  0.4065 |  2.5697 |  1.7820 |  1.7267 |  0.3841 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.2132 |  0.6031 |  0.6361 |  0.5261 | -0.1306 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.4954 | -0.0436 |  0.0842 |  0.0125 | -0.4746 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.9536 | -0.6301 | -0.5117 | -0.5702 | -1.0162 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Greatest value change compared to last iteration:\n",
      "1.9434374973177908\n",
      "--- END STATUS ---\n",
      "\n",
      "--- STATUS ---\n",
      "Grid:\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  3.3184 |  9.0971 |  4.6100 |  5.5220 |  1.5792 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  1.5451 |  3.1288 |  2.3976 |  2.0608 |  0.6778 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  0.1665 |  0.8987 |  0.8586 |  0.5583 | -0.2017 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.7432 | -0.2043 | -0.1086 | -0.3236 | -0.9137 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -1.5602 | -1.0695 | -0.9462 | -1.1254 | -1.6693 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Greatest value change compared to last iteration:\n",
      "0.13888392448425346\n",
      "--- END STATUS ---\n",
      "\n",
      "--- STATUS ---\n",
      "Grid:\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  3.3717 |  8.8436 |  4.4800 |  5.3712 |  1.5417 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  1.5796 |  3.0440 |  2.2986 |  1.9539 |  0.5933 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  0.1073 |  0.7887 |  0.7203 |  0.4035 | -0.3585 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.9171 | -0.3852 | -0.3079 | -0.5404 | -1.1386 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -1.8010 | -1.2948 | -1.1823 | -1.3777 | -1.9307 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Greatest value change compared to last iteration:\n",
      "0.010888470709323972\n",
      "--- END STATUS ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_world = GridWorld()\n",
    "iterations = 15\n",
    "discount = 0.9\n",
    "diff_arr = []\n",
    "\n",
    "def print_status(iteration):\n",
    "    print('--- STATUS ---')\n",
    "    print('Grid:')\n",
    "    #print(np.array([[tup['state_value'] for tup in row] for row in grid_world.grid]))\n",
    "    for row in grid_world.grid:\n",
    "        print('- ' * len(grid_world.grid[0]) * 5)\n",
    "        print('|', end='')\n",
    "        for cell in row:\n",
    "            cell_value = cell['state_value']\n",
    "\n",
    "            # create equal spacing for printing    \n",
    "            value_prefix = ' ' if cell_value > 0 else ''\n",
    "            value_prefix = '' if cell_value >= 10 else value_prefix\n",
    "            cell_value = round(cell_value, 4)\n",
    "            print(f' {value_prefix}{cell_value:.4f} |', end='')\n",
    "        \n",
    "        print()\n",
    "    print('- ' * len(grid_world.grid[0]) * 5)\n",
    "    print('Greatest value change compared to last iteration:')\n",
    "    print(diff_arr[iteration])\n",
    "    print('--- END STATUS ---')\n",
    "    print()\n",
    "\n",
    "iterations_to_print = [0, 1, 5, iterations - 1]\n",
    "for i in range(iterations):\n",
    "    diff = 0\n",
    "    for index, value in np.ndenumerate(grid_world.grid):\n",
    "        new_value = 0\n",
    "        for action in list(Direction):\n",
    "            reward, next_state = grid_world.move(index, action)\n",
    "            new_value += (1 / 4) * (reward + discount *\n",
    "                                    grid_world.grid[next_state]['state_value'])\n",
    "        \n",
    "        new_diff = abs(new_value - value['state_value'])\n",
    "        diff = max(diff, new_diff)\n",
    "\n",
    "        value['state_value'] = new_value\n",
    "\n",
    "    diff_arr.append(diff)\n",
    "    if i in iterations_to_print:\n",
    "        print_status(i)\n",
    "\n",
    "\n",
    "plt.plot(diff_arr)\n",
    "plt.xlabel('# Iterations')\n",
    "plt.ylabel('Greatest difference to last iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) - Action Values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachtung der Action-Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_world = GridWorld()\n",
    "iterations = 15\n",
    "discount = 0.9\n",
    "action_value_arr = np.zeros((5, 5, 4))\n",
    "diff_arr = []\n",
    "\n",
    "def action_value(action, state_index, action_value_arr):\n",
    "    new_value = 0\n",
    "    reward, next_state = grid_world.move(state_index, action)\n",
    "    for i in range(len(Direction)):\n",
    "        action_value_arr_index = next_state + (i,)\n",
    "        new_value += 1 / 4 * (action_value_arr[action_value_arr_index])\n",
    "    return reward + discount * new_value\n",
    "\n",
    "for i in range(iterations):\n",
    "    diff = 0\n",
    "    for index, _ in np.ndenumerate(grid_world.grid):\n",
    "        new_value = 0\n",
    "        for j, action in enumerate(list(Direction)):\n",
    "            new_value = action_value(action, index, action_value_arr)\n",
    "            \n",
    "            new_diff = abs(new_value - action_value_arr[index + (j,)])\n",
    "            diff = max(diff, new_diff)\n",
    "            \n",
    "            action_value_arr[index + (j,)] = new_value\n",
    "    \n",
    "    diff_arr.append(diff)\n",
    "\n",
    "plt.plot(diff_arr)\n",
    "plt.xlabel('# Iterations')\n",
    "plt.ylabel('Greatest difference to last iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the final action values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grid(grid):\n",
    "    for row in grid:\n",
    "        print('- ' * len(grid[0]) * 5)\n",
    "        print('|', end='')\n",
    "        for cell in row:\n",
    "            # create equal spacing for printing    \n",
    "            value_prefix = ' ' if cell > 0 else ''\n",
    "            value_prefix = '' if cell >= 10 else value_prefix\n",
    "            print(f' {value_prefix}{cell:.4f} |', end='')\n",
    "        \n",
    "        print()\n",
    "    print('- ' * len(grid[0]) * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final action values:\n",
      "\n",
      "RIGHT\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  7.9452 |  8.8207 |  4.8290 |  5.3574 |  0.3827 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  2.7307 |  2.0623 |  1.7538 |  0.5298 | -0.4702 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  0.7015 |  0.6414 |  0.3574 | -0.3280 | -1.3280 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.3570 | -0.2863 | -0.4947 | -1.0328 | -2.0328 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -1.1793 | -1.0768 | -1.2519 | -1.7493 | -2.7493 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "LEFT\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  2.0186 |  8.8207 |  7.9386 |  5.3574 |  4.8217 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  0.4094 |  1.4040 |  2.7239 |  2.0555 |  1.7470 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.9153 |  0.0793 |  0.6947 |  0.6348 |  0.3508 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -1.8395 | -0.8447 | -0.3635 | -0.2926 | -0.5010 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -2.6388 | -1.6436 | -1.1852 | -1.0824 | -1.2575 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "UP\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  2.0168 |  8.8207 |  3.0198 |  5.3574 |  0.3791 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  3.0131 |  7.9386 |  4.0162 |  4.8217 |  1.3755 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  1.4040 |  2.7239 |  2.0555 |  1.7470 |  0.5230 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  0.0793 |  0.6947 |  0.6348 |  0.3508 | -0.3346 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.8447 | -0.3635 | -0.2926 | -0.5010 | -1.0390 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "DOWN\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  1.4112 |  8.8207 |  2.0623 |  5.3574 |  0.5298 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "|  0.0866 |  0.7015 |  0.6414 |  0.3574 | -0.3280 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -0.8377 | -0.3570 | -0.2863 | -0.4947 | -1.0328 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -1.6372 | -1.1793 | -1.0768 | -1.2519 | -1.7493 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "| -2.6421 | -2.1838 | -2.0811 | -2.2562 | -2.7535 |\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Final action values:', end='\\n\\n')\n",
    "\n",
    "for index, _ in enumerate(list(Direction)):\n",
    "    print(list(Direction)[index].name)\n",
    "    print_grid(action_value_arr[:,:,index])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2.2 - OpenAI Gym: Implementieren der Grid-World:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.envs.registration import register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) - Erstellung der Grid-World Umgebung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen der Umgebung, sie erbt von gym.Env:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldGym(gym.Env):\n",
    "\n",
    "    metadata = {\"render_modes\": [\"ascii\"], \"render_fps\": 30}\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GridWorldGym, self).__init__()\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        \"\"\" \n",
    "        0 == UP\n",
    "        1 == DOWN\n",
    "        2 == LEFT\n",
    "        3 == RIGHT \n",
    "        \"\"\"\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=np.array([0, 0]), high=np.array([4, 4]), dtype=int)\n",
    "        self.special_states = {\n",
    "            'A': (0, 1),\n",
    "            'B': (0, 3),\n",
    "            'A_': (4, 1),\n",
    "            'B_': (2, 3)\n",
    "        }\n",
    "        self.state = np.zeros((2), dtype=int)\n",
    "        self.render_mode = 'ascii'\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)  # Ruft die Basis-Reset-Funktion mit seed auf\n",
    "\n",
    "        self.done = False\n",
    "        self.state = np.zeros((2), dtype=int)\n",
    "        return np.array(self.state), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        new_state = None\n",
    "        reward = 0\n",
    "        \n",
    "        if action == 0:\n",
    "            new_state = self.state + (-1, 0)\n",
    "        elif action == 1:\n",
    "            new_state = self.state + (1, 0)\n",
    "        elif action == 2:\n",
    "            new_state = self.state + (0, -1)\n",
    "        elif action == 3:\n",
    "            new_state = self.state + (0, 1)\n",
    "        else:\n",
    "            raise ValueError('Fehler')\n",
    "\n",
    "        if new_state[0] < 0 or new_state[1] < 0 or new_state[0] > 4 or new_state[1] > 4:\n",
    "            reward = -1\n",
    "        # @Daniel: Du hast new_state gegen \"A\" und \"B\" vergliche und dann den reward gegeben und bist in \"A\" oder \"B\" geblieben. Sofern ich das richtig verstanden habe, passte das nicht ganz. Hab das jetzt so abgeändert, dass das wie oben ist und man quasi in A und B irgendeinen Move machen kann, die Belohnung erhält und nach A_ bzw. B_ verschoben wird \n",
    "        elif np.array_equal(self.state, self.special_states[\"A\"]):\n",
    "            reward = 10\n",
    "            self.state = np.array(self.special_states[\"A_\"])\n",
    "            done = True\n",
    "        elif np.array_equal(self.state, self.special_states[\"B\"]):\n",
    "            reward = 5\n",
    "            self.state = np.array(self.special_states[\"B_\"])\n",
    "            done = True\n",
    "        else:\n",
    "            self.state = new_state\n",
    "\n",
    "        return self.state, reward, done, False, {}\n",
    "    \n",
    "    def render(self):\n",
    "        \n",
    "        if self.render_mode != 'ascii':\n",
    "            raise NotImplementedError\n",
    "\n",
    "        render_str = ''\n",
    "        for row_idx in range(5):\n",
    "            render_str += '- ' * 16\n",
    "            render_str += '\\n'\n",
    "            render_str += '|'\n",
    "            for col_idx in range(5):\n",
    "                render_str += ' '\n",
    "                \n",
    "                if np.array_equal(self.state, [row_idx, col_idx]):\n",
    "                    render_str += 'X'\n",
    "                else:\n",
    "                    render_str += ' '\n",
    "\n",
    "                if np.array_equal(self.special_states[\"A\"], [row_idx, col_idx]):\n",
    "                    render_str += 'A '\n",
    "                elif np.array_equal(self.special_states[\"A_\"], [row_idx, col_idx]):\n",
    "                    render_str += 'A_'\n",
    "                elif np.array_equal(self.special_states[\"B\"], [row_idx, col_idx]):\n",
    "                    render_str += 'B '\n",
    "                elif np.array_equal(self.special_states[\"B_\"], [row_idx, col_idx]):\n",
    "                    render_str += 'B_'\n",
    "                else:\n",
    "                    render_str += '  '\n",
    "                \n",
    "                render_str += ' |'\n",
    "            render_str += '\\n'\n",
    "        render_str += '- ' * 16\n",
    "        render_str += '\\nLegend: X = current state, A, B, A_, B_ = special states'\n",
    "\n",
    "        return render_str\n",
    "\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registrieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register(\n",
    "    id='GridWorldGym-v0',\n",
    "    entry_point=GridWorldGym,\n",
    "    max_episode_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) - Testen der Grid-World Umgebung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"GridWorldGym-v0\")\n",
    "\n",
    "\n",
    "total_reward = 0    # Gesamtbelohnung initialisieren\n",
    "done = False\n",
    "\n",
    "# speichert die Umgebungs-Visualisierung als Ascii-Strings\n",
    "visualization = []\n",
    "\n",
    "# Führe mehrere Schritte aus\n",
    "while len(visualization) < 4:\n",
    "    obs, info = env.reset()  # Setze die Umgebung zurück\n",
    "    print(obs)\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()  # Wähle eine zufällige Aktion\n",
    "        obs, reward, done, truncated, info = env.step(action)  # Führe die Aktion aus\n",
    "        total_reward += reward  # Update die Gesamtbelohnung\n",
    "        \n",
    "        if len(visualization) < 4:\n",
    "            visualization.append(env.render())\n",
    "\n",
    "        print(f\"Aktion: {action}, Neue Beobachtung: {obs}, Belohnung: {reward}, Done {done}\")\n",
    "\n",
    "print(f\"Gesamtbelohnung nach der Episode: {total_reward}\")\n",
    "\n",
    "# Visualisierung von 4 aufeinanderfolgenden Schritten (mögliches Episodenende dazwischen)\n",
    "for vis_index in range(len(visualization)):\n",
    "    vis_string = visualization[vis_index]\n",
    "    print(f'Step {vis_index}:')\n",
    "    print(vis_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2.3 - CartPole Umgebung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einfache Visualisierung mit zufällig ausgewählten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "visualization_iterations = 10\n",
    "\n",
    "for _ in range(visualization_iterations):\n",
    "    observation, info = env.reset()\n",
    "    \n",
    "    episode_over = False\n",
    "    \n",
    "    while not episode_over:\n",
    "        action = env.action_space.sample()  # random right or left\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        episode_over = terminated or truncated\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) - Implementierung eines intuitiven Lösungsansatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 100\n",
    "num_episodes = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy 1: Wenn der Pole nach links geneigt ist, fahre nach links. Wenn der Pole nach rechts geneigt ist, fahre nach rechts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, info = env.reset()\n",
    "\n",
    "rewards = np.zeros(num_episodes)\n",
    "\n",
    "for _ in range(runs):\n",
    "    \n",
    "    for episode_index in range(num_episodes):\n",
    "\n",
    "        observation, info = env.reset()\n",
    "\n",
    "        episode_over = False\n",
    "        episode_reward = 0\n",
    "\n",
    "        while not episode_over:\n",
    "            action = 1  # push cart to the right\n",
    "            \n",
    "            # if the pole is leaning to the left, push the cart to the left\n",
    "            if observation[2] < 0:\n",
    "                action = 0\n",
    "            \n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "\n",
    "            episode_over = terminated or truncated\n",
    "        \n",
    "        rewards[episode_index] += episode_reward\n",
    "\n",
    "rewards_p1 = np.divide(rewards, runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy 2: Wenn der Pole nach links geneigt ist aber eine positive Winkelgeschwindigkeit hat, fahre wieder nach rechts. Analog für Neigung nach rechts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, info = env.reset()\n",
    "\n",
    "rewards = np.zeros(num_episodes)\n",
    "\n",
    "for _ in range(runs):\n",
    "    \n",
    "    for episode_index in range(num_episodes):\n",
    "\n",
    "        observation, info = env.reset()\n",
    "\n",
    "        episode_over = False\n",
    "        episode_reward = 0\n",
    "\n",
    "        while not episode_over:\n",
    "            action = 1  # push cart to the right\n",
    "            \n",
    "            # if the pole is leaning to the left, push the cart to the left\n",
    "            falling_left = observation[3] < 0\n",
    "            if falling_left:\n",
    "                action = 0\n",
    "            \n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "\n",
    "            episode_over = terminated or truncated\n",
    "        \n",
    "        rewards[episode_index] += episode_reward\n",
    "\n",
    "rewards_p2 = np.divide(rewards, runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy 3: Zusätzliche Vermeidung des \"Herausfahrens\" aus der Umgebung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, info = env.reset()\n",
    "\n",
    "rewards = np.zeros(num_episodes)\n",
    "\n",
    "for _ in range(runs):\n",
    "\n",
    "    for episode_index in range(num_episodes):\n",
    "\n",
    "        observation, info = env.reset()\n",
    "\n",
    "        episode_over = False\n",
    "        episode_reward = 0\n",
    "\n",
    "        while not episode_over:\n",
    "            action = 1  # push cart to the right\n",
    "            \n",
    "            # if the pole is falling to the left, push the cart to the left\n",
    "            # (falling meaning the angular velocity is negative)\n",
    "            falling_left = observation[3] < 0\n",
    "            if falling_left:\n",
    "                action = 0\n",
    "            \n",
    "            # do not drive out of the environment\n",
    "            cart_position = observation[0]\n",
    "            if cart_position <= -2.2:\n",
    "                action = 1\n",
    "            elif cart_position >= 2.2:\n",
    "                action = 0\n",
    "\n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "\n",
    "            episode_over = terminated or truncated\n",
    "\n",
    "        rewards[episode_index] += episode_reward \n",
    "\n",
    "rewards_p3 = np.divide(rewards, runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment schließen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auswerten der Policy-Ergebnisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, num_episodes, num_episodes)\n",
    "\n",
    "plt.plot(x, rewards_p1, label = 'Policy 1')\n",
    "plt.plot(x, rewards_p2, label = 'Policy 2')\n",
    "plt.plot(x, rewards_p3, label = 'Policy 3')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Reward per Episode')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) - RL-Ansatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ObservationWrapper erstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DiscreteObservationWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(DiscreteObservationWrapper, self).__init__(env)\n",
    "        self.pole_pos_bins = np.array([-np.inf, 0.0, np.inf])\n",
    "        self.pole_vel_bins = np.array([-np.inf, 0.0, np.inf])\n",
    "        self.num_states = 4\n",
    "        \n",
    "        self.min_state_idx = self.get_state_index(1, 1) # since the values are always greater than negative infinity, they are always in category 1 and never in zero. Thats why category tuple (1, 1) leads to the lowest individual state index\n",
    "\n",
    "    def get_state_index(self, pole_pos_category, pole_vel_category):\n",
    "        return 2 * pole_pos_category + pole_vel_category\n",
    "\n",
    "    def observation(self, observation):\n",
    "        _, _, pole_pos, pole_vel = observation\n",
    "        \n",
    "        pole_pos_category = np.digitize(pole_pos, self.pole_pos_bins)\n",
    "        pole_vel_category = np.digitize(pole_vel, self.pole_vel_bins)\n",
    "\n",
    "        # basically binary \"or\" operation, each category gets its own bit\n",
    "        state_index = self.get_state_index(pole_pos_category, pole_vel_category)\n",
    "\n",
    "        return state_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den Banditen durch eine Klasse modellieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class StateBandit():\n",
    "    def __init__(self, epsilon, initial_Q = 0.0):\n",
    "        self.epsilon = epsilon\n",
    "        self.Q = np.array([initial_Q, initial_Q])\n",
    "        self.N = np.array([0, 0])\n",
    "        self.G = 0\n",
    "        self.reward_per_action = []\n",
    "\n",
    "    def get_action(self):\n",
    "        action = np.argmax(self.Q)\n",
    "\n",
    "        # decide on exploit vs explore\n",
    "        explore = random.random() <= self.epsilon\n",
    "        if explore:\n",
    "            action = int(random.random() >= 0.5)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def update_metrics(self, action, reward):\n",
    "        self.reward_per_action.append(reward)\n",
    "        self.G += reward\n",
    "        self.N[action] += 1\n",
    "        self.Q[action] = self.Q[action] + ((reward - self.Q[action]) / self.N[action])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für jeden State einen Banditen erstellen und die Simulation laufen lassen, um die Banditen anzulernen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stdout # flushing stdout for progress printing\n",
    "\n",
    "# create env with wrapper\n",
    "env = gym.make('CartPole-v1')\n",
    "wrapped_env = DiscreteObservationWrapper(env)\n",
    "\n",
    "# setting up the bandits\n",
    "epsilon_value = 0.1\n",
    "initial_Q = 1.0\n",
    "bandits = [StateBandit(epsilon_value, initial_Q) for _ in range(wrapped_env.num_states)]\n",
    "\n",
    "# training parameters\n",
    "simulation_steps = 40_000\n",
    "\n",
    "# reset wrapped env\n",
    "state_index, _ = wrapped_env.reset()\n",
    "episode_over = False\n",
    "\n",
    "# training loop\n",
    "progress = -1\n",
    "sim_step = 0\n",
    "while sim_step < simulation_steps:\n",
    "    \n",
    "    new_progress = int(((sim_step + 1) * 100) / simulation_steps)\n",
    "    if new_progress > progress:\n",
    "        progress = new_progress\n",
    "        print(f'\\rProgress: {progress} %', end='')\n",
    "        stdout.flush()\n",
    "\n",
    "    bandit_index = state_index - wrapped_env.min_state_idx\n",
    "    action = bandits[bandit_index].get_action()\n",
    "    state_index, reward, terminated, truncated, _ = wrapped_env.step(action)\n",
    "\n",
    "    reward = -10 if terminated else reward\n",
    "\n",
    "    bandits[bandit_index].update_metrics(action, reward)\n",
    "\n",
    "    episode_over = terminated or truncated\n",
    "    \n",
    "    if episode_over:\n",
    "        sim_step += 1\n",
    "        episode_over = False\n",
    "        state_index, _ = wrapped_env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotten des Lernprozesses, Nutzung eines \"Dictionarys\", Banditen-Index auf die Zustandsbeschreibung zu mappen. Die Verwendung eines vollwertigen Python-Dicts ist hier nicht notwendig, da die Banditen von Index 0 aufsteigend geplottet werden. Das heißt, man kann die Zustandsbeschreibungen auch chronologisch ablegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_index_description = ['Negative angle, negative velocity', 'Negative angle, positive velocity', 'Positive angle, Negative velocity', 'Positive angle, Positive velocity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(bandits), figsize=(15, 15))\n",
    "for bandit_index in range(len(bandits)):\n",
    "    bandit = bandits[bandit_index]\n",
    "    ax[bandit_index].plot(bandit.reward_per_action, label = f'State {bandit_index} ({state_index_description[bandit_index]})')\n",
    "    ax[bandit_index].set_xlabel('# Actions')\n",
    "    ax[bandit_index].set_ylabel('Reward per Action')\n",
    "    ax[bandit_index].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testen, wie gut die Banditen sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 200\n",
    "runs = 100\n",
    "\n",
    "state_index, info = wrapped_env.reset()\n",
    "\n",
    "rewards = np.zeros(num_episodes)\n",
    "\n",
    "for _ in range(runs):\n",
    "    \n",
    "    for episode_index in range(num_episodes):\n",
    "\n",
    "        state_index, info = wrapped_env.reset()\n",
    "\n",
    "        episode_over = False\n",
    "        episode_reward = 0\n",
    "\n",
    "        while not episode_over:\n",
    "            bandit_index = state_index - wrapped_env.min_state_idx\n",
    "            action = bandits[bandit_index].get_action()\n",
    "\n",
    "            state_index, reward, terminated, truncated, info = wrapped_env.step(action)\n",
    "            episode_reward += reward\n",
    "\n",
    "            episode_over = terminated or truncated\n",
    "        \n",
    "        rewards[episode_index] += episode_reward\n",
    "\n",
    "rewards_RL = np.divide(rewards, runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung der Testergebnisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, num_episodes, num_episodes)\n",
    "\n",
    "plt.plot(x, rewards_RL, label = 'Reinforcement Learning')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Reward per Episode')\n",
    "plt.ylim(0, 240)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schließen der Environments (Da diese noch für den Test verwendet wurden, kann man sie nicht direkt nach dem Training schließen):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_env.close()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_reinforcement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
